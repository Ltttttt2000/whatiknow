概念：从**大量**数据提取人们事先不知道的，有价值的信息和知识的过程。
数据：大量的、不完全的、有噪声的、随机的实际数据，信息和知识，包括研究对象间的关系、模式类别和发展趋势等方面。
分类：
1. 关联规则算法：找重复出现概率很高的模式
2. 分类算法：利用分类函数/模型映射到类别
3. 聚类算法：无监督
4. 时间序列分析：动态数据处理，基于时间

过程：
1. 数据准备：提供高质量输入数据，数据净化、集成、变换、规约
2. 模式发现：核心阶段。确定任务选择算法
3. 挖掘结果：关注于规则和模式化的可视化表示
研究方法：
1. 统计分析法：回归分析（依赖关系变量间）；主成成分分析（降维）
2. 决策树方法：近离散，每个分支信息提取规则
3. 模糊集方法：二值逻辑-->无穷多值
4. 人工神经网络
5. 遗传算法：搜索最优解

### 数据预处理
一、 清洗：处理缺失值、异常值
缺失值：删除/填充（均值、众数、其他）
异常值：插值、平滑
重复值：删除/合并成一个值

二、 转换：归一化、标准化（特征缩放Scaling）
MinMaxScaler
归一化Normalization：将数据按比例缩放到一个特定区间
最小-最大归一$X_{norm}=\frac{X-X_{min}}{X_{max}-X_{min}}$
很依赖于最大最小值-->对异常值非常敏感

StandardScaler
标准化Standardization：将数据转换为均值为0、方差为1的标准正态分布
对异常值不太敏感，缩放后符合标准正态分布N(0,1)
Z-score标准化 $Z=\frac{X-\mu}{\sigma}$

小数定标标准化 $X=\frac{X}{10^d}$ 使abs<1
Log转换
softmax归一 $P(class_{i})=\frac{e^(Z_{i})}{\sum e^(Z_{j})}$ 多分类

三、规约：减少维度
防治过拟合 PCA等

### 特征选择

1. 过滤式方法：选相关性高的e.g.方差选择，相关系数卡方检验
2. 包裹式方法：特定模型训练，评估子集e.g. 递归特征消除RFE，前向选择后向删除
3. 嵌入式方法：模型训练中自动选特征e.g.LASSO回归决策树剪枝
### 特征提取
- 主成成分分析PCA：线性变换到新坐标轴
- 线性判别器分析LDA：PCA考虑了类别信息
- t-分布邻域嵌入t-SNE：非线性将维，保留相似结构
- 自编码器Autoencoder：神经网络压缩
- 字典学习：减少特征冗余
### 关联规则挖掘：Apriori, FP-growth
Apriori: 发现频繁项集
先验原理，若一个项集频繁，则所有子项集频繁。
Steps: 生成候选集-计算支持度-筛选频繁集-生成关联规则-计算置信度-选关联规则
$$
support(X,Y)=P(X,Y)=\frac{num(x,y)}{num(all)} ,
confidence(X,Y)=P(X|Y)=\frac{P(xy)}{P(y)}
$$
FP-growth：基于频繁模式的增长方法
快于Apriori，但不能发现关联规则，构建FP树，挖掘频繁项集。
